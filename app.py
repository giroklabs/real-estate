from flask import Flask, jsonify, request
from flask_cors import CORS
import sqlite3
import json
import gzip
from datetime import datetime, timedelta
import os
from database.models import init_db
from crawlers.reb_api_crawler import REBAPICrawler
from crawlers.public_data_crawler import PublicDataCrawler

# ì„ íƒì  ì˜ì¡´ì„±(ì…€ë ˆë‹ˆì›€ ë“±)ì— ì˜ì¡´í•˜ëŠ” í¬ë¡¤ëŸ¬ëŠ” ì§€ì—°/ì˜µì…˜ ì„í¬íŠ¸ë¡œ ì²˜ë¦¬
try:
    from crawlers.asil_crawler import AsilCrawler  # requires selenium
except Exception:
    AsilCrawler = None
try:
    from crawlers.molit_api_crawler import MolitAPICrawler  # may require pandas/numpy
except Exception:
    MolitAPICrawler = None
try:
    from crawlers.molit_web_crawler import MolitWebCrawler
except Exception:
    MolitWebCrawler = None
try:
    from crawlers.web_scraper import WebScraper  # optional dependency (selenium)
except Exception:
    WebScraper = None
from services.region_service import RegionService

# Gzip ì••ì¶• í—¬í¼ í•¨ìˆ˜
def create_gzipped_response(data, status_code=200):
    """Gzip ì••ì¶•ëœ JSON ì‘ë‹µ ìƒì„±"""
    json_data = json.dumps(data, ensure_ascii=False)
    gzip_data = gzip.compress(json_data.encode('utf-8'))
    
    response = jsonify(data)
    response.headers['Content-Encoding'] = 'gzip'
    response.headers['Content-Length'] = len(gzip_data)
    response.headers['Vary'] = 'Accept-Encoding'
    response.status_code = status_code
    
    # Flaskì˜ jsonifyì™€ gzipì„ í•¨ê»˜ ì‚¬ìš©í•˜ê¸° ìœ„í•œ ì²˜ë¦¬
    response.data = gzip_data
    response.mimetype = 'application/json'
    
    return response

# ì €ì¥ëœ ë°ì´í„° ë¡œë“œ í•¨ìˆ˜
def load_saved_busan_data():
    """ì €ì¥ëœ ë¶€ì‚° ë°ì´í„° ë¡œë“œ"""
    try:
        data_dir = "collected_data"
        all_data_filename = f"{data_dir}/busan_all_data.json"
        
        if os.path.exists(all_data_filename):
            with open(all_data_filename, 'r', encoding='utf-8') as f:
                return json.load(f)
        else:
            print("ì €ì¥ëœ ë¶€ì‚° ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
    except Exception as e:
        print(f"ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {e}")
        return None

def load_saved_busan_incheon_seoul_data():
    """ì €ì¥ëœ ë¶€ì‚°+ì¸ì²œ+ì„œìš¸ ë°ì´í„° ë¡œë“œ"""
    try:
        data_dir = "collected_data"
        all_data_filename = f"{data_dir}/busan_incheon_seoul_all_data.json"
        
        if os.path.exists(all_data_filename):
            with open(all_data_filename, 'r', encoding='utf-8') as f:
                return json.load(f)
        else:
            print("ì €ì¥ëœ ë¶€ì‚°+ì¸ì²œ+ì„œìš¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
    except Exception as e:
        print(f"ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {e}")
        return None

def load_saved_busan_incheon_seoul_daegu_data():
    """ì €ì¥ëœ ë¶€ì‚°+ì¸ì²œ+ì„œìš¸+ëŒ€êµ¬ ë°ì´í„° ë¡œë“œ"""
    try:
        data_dir = "collected_data"
        all_data_filename = f"{data_dir}/busan_incheon_seoul_daegu_all_data.json"
        
        if os.path.exists(all_data_filename):
            with open(all_data_filename, 'r', encoding='utf-8') as f:
                return json.load(f)
        else:
            print("ì €ì¥ëœ ë¶€ì‚°+ì¸ì²œ+ì„œìš¸+ëŒ€êµ¬ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
    except Exception as e:
        print(f"ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {e}")
        return None

def load_saved_busan_incheon_seoul_daegu_bucheon_data():
    """ì €ì¥ëœ ë¶€ì‚°+ì¸ì²œ+ì„œìš¸+ëŒ€êµ¬+ë¶€ì²œ ë°ì´í„° ë¡œë“œ"""
    try:
        data_dir = "collected_data"
        all_data_filename = f"{data_dir}/busan_incheon_seoul_daegu_bucheon_all_data.json"
        
        if os.path.exists(all_data_filename):
            with open(all_data_filename, 'r', encoding='utf-8') as f:
                return json.load(f)
        else:
            print("ì €ì¥ëœ ë¶€ì‚°+ì¸ì²œ+ì„œìš¸+ëŒ€êµ¬+ë¶€ì²œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
    except Exception as e:
        print(f"ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {e}")
        return None

def load_saved_seongnam_data():
    """ì €ì¥ëœ ì„±ë‚¨ì‹œ ë°ì´í„° ë¡œë“œ"""
    try:
        data_dir = "collected_data"
        all_data_filename = f"{data_dir}/seongnam_all_data.json"
        
        if os.path.exists(all_data_filename):
            with open(all_data_filename, 'r', encoding='utf-8') as f:
                return json.load(f)
        else:
            print("ì €ì¥ëœ ì„±ë‚¨ì‹œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
    except Exception as e:
        print(f"ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {e}")
        return None

def load_saved_guri_data():
    """ì €ì¥ëœ êµ¬ë¦¬ì‹œ ë°ì´í„° ë¡œë“œ"""
    try:
        data_dir = "collected_data"
        all_data_filename = f"{data_dir}/guri_all_data.json"
        
        if os.path.exists(all_data_filename):
            with open(all_data_filename, 'r', encoding='utf-8') as f:
                return json.load(f)
        else:
            print("ì €ì¥ëœ êµ¬ë¦¬ì‹œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
    except Exception as e:
        print(f"ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {e}")
        return None

app = Flask(__name__)
CORS(app)

# ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
init_db()

# ì§€ì—­ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
region_service = RegionService()

@app.route('/api/health', methods=['GET'])
def health_check():
    """ì„œë²„ ìƒíƒœ í™•ì¸"""
    return jsonify({'status': 'healthy', 'timestamp': datetime.now().isoformat()})

@app.route('/api/busan-data', methods=['GET'])
def get_busan_data():
    """ì €ì¥ëœ ë¶€ì‚° ì „ì²´ êµ¬ ë°ì´í„° ì¡°íšŒ"""
    try:
        data = load_saved_busan_data()
        if data:
            return jsonify({
                'status': 'success',
                'data': data,
                'message': 'ì €ì¥ëœ ë¶€ì‚° ë°ì´í„°ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.'
            })
        else:
            return jsonify({
                'status': 'error',
                'message': 'ì €ì¥ëœ ë¶€ì‚° ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•´ì£¼ì„¸ìš”.'
            }), 404
    except Exception as e:
        return jsonify({
            'status': 'error',
            'message': f'ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'
        }), 500

@app.route('/api/busan-data/<region>', methods=['GET'])
def get_busan_region_data(region):
    """íŠ¹ì • ë¶€ì‚° êµ¬/êµ° ë°ì´í„° ì¡°íšŒ"""
    try:
        data = load_saved_busan_data()
        if data and region in data:
            return jsonify({
                'status': 'success',
                'region': region,
                'data': data[region],
                'transaction_count': len(data[region])
            })
        else:
            return jsonify({
                'status': 'error',
                'message': f'{region} ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
            }), 404
    except Exception as e:
        return jsonify({
            'status': 'error',
            'message': f'ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'
        }), 500

@app.route('/api/busan-incheon-seoul-data', methods=['GET'])
def get_busan_incheon_seoul_data():
    """ì €ì¥ëœ ë¶€ì‚°+ì¸ì²œ+ì„œìš¸ ì „ì²´ êµ¬ ë°ì´í„° ì¡°íšŒ"""
    try:
        data = load_saved_busan_incheon_seoul_data()
        if data:
            return jsonify({
                'status': 'success',
                'data': data,
                'message': 'ì €ì¥ëœ ë¶€ì‚°+ì¸ì²œ+ì„œìš¸ ë°ì´í„°ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.'
            })
        else:
            return jsonify({
                'status': 'error',
                'message': 'ì €ì¥ëœ ë¶€ì‚°+ì¸ì²œ+ì„œìš¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•´ì£¼ì„¸ìš”.'
            }), 404
    except Exception as e:
        return jsonify({
            'status': 'error',
            'message': f'ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'
        }), 500

@app.route('/api/busan-incheon-seoul-daegu-data', methods=['GET'])
def get_busan_incheon_seoul_daegu_data():
    """ì €ì¥ëœ ë¶€ì‚°+ì¸ì²œ+ì„œìš¸+ëŒ€êµ¬ ì „ì²´ êµ¬ ë°ì´í„° ì¡°íšŒ"""
    try:
        data = load_saved_busan_incheon_seoul_daegu_data()
        if data:
            return jsonify({
                'status': 'success',
                'data': data,
                'message': 'ì €ì¥ëœ ë¶€ì‚°+ì¸ì²œ+ì„œìš¸+ëŒ€êµ¬ ë°ì´í„°ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.'
            })
        else:
            return jsonify({
                'status': 'error',
                'message': 'ì €ì¥ëœ ë¶€ì‚°+ì¸ì²œ+ì„œìš¸+ëŒ€êµ¬ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•´ì£¼ì„¸ìš”.'
            }), 404
    except Exception as e:
        return jsonify({
            'status': 'error',
            'message': f'ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'
        }), 500

@app.route('/api/busan-incheon-seoul-daegu-bucheon-data', methods=['GET'])
def get_busan_incheon_seoul_daegu_bucheon_data():
    """ì €ì¥ëœ ë¶€ì‚°+ì¸ì²œ+ì„œìš¸+ëŒ€êµ¬+ë¶€ì²œ ì „ì²´ êµ¬ ë°ì´í„° ì¡°íšŒ"""
    try:
        data = load_saved_busan_incheon_seoul_daegu_bucheon_data()
        if data:
            response_data = {
                'status': 'success',
                'data': data,
                'message': 'ì €ì¥ëœ ë¶€ì‚°+ì¸ì²œ+ì„œìš¸+ëŒ€êµ¬+ë¶€ì²œ ë°ì´í„°ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.'
            }
            return create_gzipped_response(response_data)
        else:
            error_data = {
                'status': 'error',
                'message': 'ì €ì¥ëœ ë¶€ì‚°+ì¸ì²œ+ì„œìš¸+ëŒ€êµ¬+ë¶€ì²œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•´ì£¼ì„¸ìš”.'
            }
            return create_gzipped_response(error_data, 404)
    except Exception as e:
        error_data = {
            'status': 'error',
            'message': f'ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'
        }
        return create_gzipped_response(error_data, 500)

@app.route('/api/seongnam-data', methods=['GET'])
def get_seongnam_data():
    """ì €ì¥ëœ ì„±ë‚¨ì‹œ ì „ì²´ êµ¬ ë°ì´í„° ì¡°íšŒ"""
    try:
        data = load_saved_seongnam_data()
        if data:
            return jsonify({
                'status': 'success',
                'data': data,
                'message': 'ì €ì¥ëœ ì„±ë‚¨ì‹œ ë°ì´í„°ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.'
            })
        else:
            return jsonify({
                'status': 'error',
                'message': 'ì €ì¥ëœ ì„±ë‚¨ì‹œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•´ì£¼ì„¸ìš”.'
            }), 404
    except Exception as e:
        return jsonify({
            'status': 'error',
            'message': f'ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'
        }), 500

@app.route('/api/guri-data', methods=['GET'])
def get_guri_data():
    """ì €ì¥ëœ êµ¬ë¦¬ì‹œ ë°ì´í„° ì¡°íšŒ"""
    try:
        data = load_saved_guri_data()
        if data:
            return jsonify({
                'status': 'success',
                'data': data,
                'message': 'ì €ì¥ëœ êµ¬ë¦¬ì‹œ ë°ì´í„°ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.'
            })
        else:
            return jsonify({
                'status': 'error',
                'message': 'ì €ì¥ëœ êµ¬ë¦¬ì‹œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•´ì£¼ì„¸ìš”.'
            }), 404
    except Exception as e:
        return jsonify({
            'status': 'error',
            'message': f'ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'
        }), 500

@app.route('/api/all-cities-data', methods=['GET'])
def get_all_cities_data():
    """ì €ì¥ëœ ëª¨ë“  ë„ì‹œ ë°ì´í„° ì¡°íšŒ (ë¶€ì‚°+ì¸ì²œ+ì„œìš¸+ëŒ€êµ¬+ë¶€ì²œ+ì„±ë‚¨+êµ¬ë¦¬)"""
    try:
        # ê¸°ì¡´ í†µí•© ë°ì´í„° ë¡œë“œ
        base_data = load_saved_busan_incheon_seoul_daegu_bucheon_data()
        
        # ì„±ë‚¨ì‹œ ë°ì´í„° ì¶”ê°€
        seongnam_data = load_saved_seongnam_data()
        if seongnam_data:
            if base_data is None:
                base_data = {}
            base_data.update(seongnam_data)
        
        # êµ¬ë¦¬ì‹œ ë°ì´í„° ì¶”ê°€
        guri_data = load_saved_guri_data()
        if guri_data:
            if base_data is None:
                base_data = {}
            base_data.update(guri_data)
        
        if base_data:
            return jsonify({
                'status': 'success',
                'data': base_data,
                'message': 'ì €ì¥ëœ ëª¨ë“  ë„ì‹œ ë°ì´í„°ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.'
            })
        else:
            return jsonify({
                'status': 'error',
                'message': 'ì €ì¥ëœ ë„ì‹œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•´ì£¼ì„¸ìš”.'
            }), 404
    except Exception as e:
        return jsonify({
            'status': 'error',
            'message': f'ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'
        }), 500

def load_saved_integrated_data():
    """ì €ì¥ëœ í†µí•© ë°ì´í„° ë¡œë“œ"""
    try:
        data_dir = "collected_data"
        all_data_filename = f"{data_dir}/all_cities_integrated_data.json"
        
        if os.path.exists(all_data_filename):
            with open(all_data_filename, 'r', encoding='utf-8') as f:
                return json.load(f)
        else:
            print("ì €ì¥ëœ í†µí•© ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
    except Exception as e:
        print(f"í†µí•© ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {e}")
        return None

@app.route('/api/seoul-district-data', methods=['GET'])
def get_seoul_district_data():
    """ì„œìš¸ì‹œ íŠ¹ì • êµ¬ ë°ì´í„° ì¡°íšŒ"""
    try:
        district = request.args.get('district', '')
        if not district:
            return jsonify({
                'status': 'error',
                'message': 'êµ¬ ì´ë¦„ì„ ì§€ì •í•´ì£¼ì„¸ìš”'
            }), 400
        
        # ì„œìš¸ì‹œ êµ¬ ë°ì´í„° íŒŒì¼ ê²½ë¡œ
        file_path = os.path.join('collected_data', f'ì„œìš¸_{district}_data.json')
        
        if not os.path.exists(file_path):
            return jsonify({
                'status': 'error',
                'message': f'ì„œìš¸ {district} ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤ (ê²½ë¡œ: {file_path})'
            }), 404
        
        # ë°ì´í„° ë¡œë“œ
        with open(file_path, 'r', encoding='utf-8') as f:
            district_data = json.load(f)
        
        response_data = {
            'status': 'success',
            'data': district_data,
            'district': district,
            'transaction_count': len(district_data) if isinstance(district_data, list) else 0
        }
        
        return jsonify(response_data)
        
    except Exception as e:
        return jsonify({
            'status': 'error',
            'message': f'ì„œìš¸ {district} ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'
        }), 500

@app.route('/api/seoul-priority-data', methods=['GET'])
def get_seoul_priority_data():
    """ì„œìš¸ì‹œ ìš°ì„  ë°ì´í„° ì¡°íšŒ (ë¹ ë¥¸ ë¡œë”©ìš©)"""
    try:
        # ì„œìš¸ì‹œ ìš°ì„  ë°ì´í„° ìƒì„±
        seoul_priority_data = create_seoul_priority_data()
        
        response_data = {
            'status': 'success',
            'data': seoul_priority_data,
            'type': 'seoul_priority',
            'metadata': {
                'collection_date': datetime.now().isoformat(),
                'total_regions': len(seoul_priority_data),
                'data_size_mb': round(len(json.dumps(seoul_priority_data, ensure_ascii=False).encode('utf-8')) / (1024 * 1024), 2),
                'description': 'ì„œìš¸ì‹œ 1ê°œì›” ìš°ì„  ë°ì´í„° (ë¹ ë¥¸ ë¡œë”©ìš©)'
            }
        }
        
        return jsonify(response_data)
        
    except Exception as e:
        return jsonify({
            'status': 'error',
            'message': f'ì„œìš¸ì‹œ ìš°ì„  ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'
        }), 500



def create_seoul_priority_data():
    """ì„œìš¸ì‹œ ìš°ì„  ë°ì´í„° ìƒì„± - ì„œìš¸ì‹œ 25ê°œ êµ¬ ë°ì´í„°ë§Œ í¬í•¨"""
    
    seoul_priority_data = {}
    
    # ì„œìš¸ì‹œ êµ¬ ëª©ë¡
    seoul_districts = [
        'ê°•ë‚¨êµ¬', 'ê°•ë™êµ¬', 'ê°•ë¶êµ¬', 'ê°•ì„œêµ¬', 'ê´€ì•…êµ¬', 'ê´‘ì§„êµ¬', 'êµ¬ë¡œêµ¬', 'ê¸ˆì²œêµ¬',
        'ë…¸ì›êµ¬', 'ë„ë´‰êµ¬', 'ë™ëŒ€ë¬¸êµ¬', 'ë™ì‘êµ¬', 'ë§ˆí¬êµ¬', 'ì„œëŒ€ë¬¸êµ¬', 'ì„œì´ˆêµ¬', 'ì„±ë™êµ¬',
        'ì„±ë¶êµ¬', 'ì†¡íŒŒêµ¬', 'ì–‘ì²œêµ¬', 'ì˜ë“±í¬êµ¬', 'ìš©ì‚°êµ¬', 'ì€í‰êµ¬', 'ì¢…ë¡œêµ¬', 'ì¤‘êµ¬', 'ì¤‘ë‘êµ¬'
    ]
    
    # ê° ì„œìš¸ì‹œ êµ¬ì˜ ë°ì´í„° íŒŒì¼ì—ì„œ ë°ì´í„° ë¡œë“œ
    for district in seoul_districts:
        file_path = os.path.join('collected_data', f'ì„œìš¸_{district}_data.json')
        
        if os.path.exists(file_path):
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    district_data = json.load(f)
                
                # ì„œìš¸ì‹œ ìš°ì„  ë°ì´í„°ì— ì¶”ê°€
                seoul_priority_data[f'ì„œìš¸ {district}'] = district_data
                print(f"âœ… ì„œìš¸ {district} ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
                
            except Exception as e:
                print(f"âŒ ì„œìš¸ {district} ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
                continue
    
    # ìš°ì„  ë°ì´í„° íŒŒì¼ë¡œ ì €ì¥ (ë‹¤ìŒë²ˆ ìš”ì²­ ì‹œ ë¹ ë¥¸ ë¡œë”©)
    try:
        priority_path = os.path.join('collected_data', 'seoul_priority_data.json')
        with open(priority_path, 'w', encoding='utf-8') as f:
            json.dump(seoul_priority_data, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ ì„œìš¸ì‹œ ìš°ì„  ë°ì´í„° íŒŒì¼ ì €ì¥ ì™„ë£Œ: {priority_path}")
    except Exception as e:
        print(f"âŒ ì„œìš¸ì‹œ ìš°ì„  ë°ì´í„° íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    return seoul_priority_data

@app.route('/api/integrated-data', methods=['GET'])
def get_integrated_data():
    """ì €ì¥ëœ í†µí•© ë°ì´í„° ì¡°íšŒ (ë©”íƒ€ë°ì´í„° í¬í•¨)"""
    try:
        data = load_saved_integrated_data()
        if data:
            return jsonify({
                'status': 'success',
                'data': data['data'],
                'metadata': data['metadata'],
                'message': 'ì €ì¥ëœ í†µí•© ë°ì´í„°ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.'
            })
        else:
            return jsonify({
                'status': 'error',
                'message': 'ì €ì¥ëœ í†µí•© ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•´ì£¼ì„¸ìš”.'
            }), 404
    except Exception as e:
        return jsonify({
            'status': 'error',
            'message': f'ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'
        }), 500

@app.route('/api/integrated-data-chunked', methods=['GET'])
def get_integrated_data_chunked():
    """ì²­í¬ ë‹¨ìœ„ë¡œ í†µí•© ë°ì´í„° ì œê³µ (ì„±ëŠ¥ í–¥ìƒ)"""
    try:
        chunk_size = request.args.get('chunk_size', 1000, type=int)
        page = request.args.get('page', 0, type=int)
        
        data = load_saved_integrated_data()
        if not data:
            return jsonify({'status': 'error', 'message': 'ë°ì´í„° ì—†ìŒ'}), 404
        
        # ë°ì´í„°ë¥¼ ì²­í¬ë¡œ ë¶„í• 
        all_items = []
        for region_data in data['data'].values():
            if isinstance(region_data, list):
                all_items.extend(region_data)
        
        start_idx = page * chunk_size
        end_idx = start_idx + chunk_size
        chunk_data = all_items[start_idx:end_idx]
        
        return jsonify({
            'status': 'success',
            'data': chunk_data,
            'pagination': {
                'page': page,
                'chunk_size': chunk_size,
                'total_items': len(all_items),
                'has_more': end_idx < len(all_items)
            }
        })
    except Exception as e:
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/busan-summary', methods=['GET'])
def get_busan_summary():
    """ë¶€ì‚° ì „ì²´ êµ¬ ë°ì´í„° ìš”ì•½ ì •ë³´"""
    try:
        data = load_saved_busan_data()
        print(f"ë¡œë“œëœ ë°ì´í„°: {type(data)}, í‚¤: {list(data.keys()) if data else 'None'}")
        
        if data:
            summary = {
                'total_regions': len(data),
                'total_transactions': sum(len(region_data) for region_data in data.values()),
                'regions_summary': {}
            }
            
            for region, region_data in data.items():
                print(f"ì²˜ë¦¬ ì¤‘ì¸ ì§€ì—­: {region}, ë°ì´í„° ìˆ˜: {len(region_data) if region_data else 0}")
                if region_data:
                    # ì´ë¯¸ ê³„ì‚°ëœ avg_price, max_price, min_price ì‚¬ìš©
                    prices = []
                    for item in region_data:
                        if 'avg_price' in item and item['avg_price']:
                            try:
                                price = int(item['avg_price'])
                                prices.append(price)
                            except (ValueError, TypeError):
                                continue
                    
                    print(f"  {region} ê°€ê²© ë°ì´í„°: {len(prices)}ê°œ, ìƒ˜í”Œ: {prices[:3] if prices else 'None'}")
                    
                    if prices:
                        avg_price = int(sum(prices) / len(prices))
                        max_price = max(prices)
                        min_price = min(prices)
                    else:
                        avg_price = 0
                        max_price = 0
                        min_price = 0
                    
                    summary['regions_summary'][region] = {
                        'transaction_count': len(region_data),
                        'avg_price': avg_price,
                        'max_price': max_price,
                        'min_price': min_price
                    }
            
            return jsonify({
                'status': 'success',
                'summary': summary
            })
        else:
            return jsonify({
                'status': 'error',
                'message': 'ì €ì¥ëœ ë¶€ì‚° ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.'
            }), 404
    except Exception as e:
        return jsonify({
            'status': 'error',
            'message': f'ìš”ì•½ ì •ë³´ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'
        }), 500

@app.route('/api/regions', methods=['GET'])
def get_regions():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ì‹œêµ°êµ¬ ëª©ë¡ (ì§€ì—­ ì„œë¹„ìŠ¤ ê¸°ë°˜)"""
    try:
        # ë¨¼ì € DBì—ì„œ ì‹¤ì œ ë°ì´í„°ê°€ ìˆëŠ” ì§€ì—­ë“¤ì„ ì¡°íšŒ
        conn = sqlite3.connect(os.environ.get('DATABASE_PATH', '/tmp/realstate.db'))
        cursor = conn.cursor()
        
        cursor.execute('SELECT DISTINCT region_name FROM transactions ORDER BY region_name')
        db_regions = [row[0] for row in cursor.fetchall()]
        conn.close()
        
        # ì§€ì—­ ì„œë¹„ìŠ¤ì—ì„œ ì§€ì›í•˜ëŠ” ì§€ì—­ ëª©ë¡ê³¼ êµì§‘í•©
        supported_regions = region_service.get_regions_for_api()
        
        # DBì— ë°ì´í„°ê°€ ìˆìœ¼ë©´ì„œ ì§€ì›í•˜ëŠ” ì§€ì—­ë“¤ì„ ìš°ì„  ë°˜í™˜
        available_regions = [r for r in db_regions if region_service.is_supported_region(r)]
        
        # DBì— ë°ì´í„°ê°€ ì—†ë‹¤ë©´ ì§€ì›í•˜ëŠ” ëª¨ë“  ì§€ì—­ ë°˜í™˜
        if not available_regions:
            available_regions = supported_regions
        
        return jsonify(available_regions)
        
    except Exception as e:
        print(f"Error in get_regions: {str(e)}")
        # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ ì§€ì—­ ë°˜í™˜
        return jsonify(region_service.get_default_regions())

@app.route('/api/provinces', methods=['GET'])
def get_provinces():
    """ì§€ì›í•˜ëŠ” ê´‘ì—­ì‹œ/ë„ ëª©ë¡"""
    try:
        provinces = region_service.get_supported_provinces()
        return jsonify(provinces)
    except Exception as e:
        print(f"Error in get_provinces: {str(e)}")
        return jsonify([])

@app.route('/api/provinces/<province_name>/districts', methods=['GET'])
def get_districts_by_province(province_name):
    """íŠ¹ì • ê´‘ì—­ì‹œ/ë„ì˜ êµ¬/êµ° ëª©ë¡"""
    try:
        districts = region_service.get_districts_by_province(province_name)
        
        # í‘œì¤€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        formatted_districts = []
        for district_name in districts.keys():
            formatted_name = region_service.format_region_name(province_name, district_name)
            formatted_districts.append({
                'name': formatted_name,
                'district': district_name,
                'code': districts[district_name]
            })
        
        return jsonify(formatted_districts)
    except Exception as e:
        print(f"Error in get_districts_by_province: {str(e)}")
        return jsonify([])

@app.route('/api/regions/validate', methods=['POST'])
def validate_regions():
    """ìš”ì²­ëœ ì§€ì—­ì´ ì§€ì› ë²”ìœ„ ë‚´ì¸ì§€ í™•ì¸"""
    try:
        data = request.get_json()
        regions = data.get('regions', [])
        
        valid, unsupported = region_service.validate_region_request(regions)
        
        return jsonify({
            'valid': valid,
            'unsupported_regions': unsupported,
            'supported_regions': [r for r in regions if region_service.is_supported_region(r)]
        })
    except Exception as e:
        print(f"Error in validate_regions: {str(e)}")
        return jsonify({'valid': False, 'error': str(e)}), 500

@app.route('/api/transactions', methods=['GET'])
def get_transactions():
    """ê±°ë˜ ë°ì´í„° ì¡°íšŒ"""
    region = request.args.get('region', '')
    start_date = request.args.get('start_date', '')
    end_date = request.args.get('end_date', '')
    
    conn = sqlite3.connect(os.environ.get('DATABASE_PATH', '/tmp/realstate.db'))
    cursor = conn.cursor()
    
    query = '''
        SELECT 
            t.date,
            t.region_name,
            t.complex_name,
            t.transaction_count,
            t.avg_price,
            t.source
        FROM transactions t
        WHERE 1=1
    '''
    params = []
    
    if region:
        query += ' AND t.region_name = ?'
        params.append(region)
    
    if start_date:
        query += ' AND t.date >= ?'
        params.append(start_date)
    
    if end_date:
        query += ' AND t.date <= ?'
        params.append(end_date)
    
    query += ' ORDER BY t.date DESC'
    
    cursor.execute(query, params)
    transactions = []
    
    for row in cursor.fetchall():
        transactions.append({
            'date': row[0],
            'region_name': row[1],
            'complex_name': row[2],
            'transaction_count': row[3],
            'avg_price': row[4],
            'source': row[5]
        })
    
    conn.close()
    return jsonify(transactions)

@app.route('/api/price-changes', methods=['GET'])
def get_price_changes():
    """ê°€ê²©ë³€ë™ë¥  ë°ì´í„° ì¡°íšŒ"""
    region = request.args.get('region', '')
    period = request.args.get('period', '30')  # ê¸°ë³¸ 30ì¼
    
    conn = sqlite3.connect(os.environ.get('DATABASE_PATH', '/tmp/realstate.db'))
    cursor = conn.cursor()
    
    query = '''
        SELECT 
            date,
            region_name,
            avg_price,
            price_change_rate
        FROM price_changes
        WHERE 1=1
    '''
    params = []
    
    if region:
        query += ' AND region_name = ?'
        params.append(region)
    
    query += ' ORDER BY date DESC LIMIT ?'
    params.append(int(period))
    
    cursor.execute(query, params)
    price_changes = []
    
    for row in cursor.fetchall():
        price_changes.append({
            'date': row[0],
            'region_name': row[1],
            'avg_price': row[2],
            'price_change_rate': row[3]
        })
    
    conn.close()
    return jsonify(price_changes)

@app.route('/api/crawl', methods=['POST'])
def start_crawling():
    """í¬ë¡¤ë§ ì‘ì—… ì‹œì‘ (ì§€ì—­ ì„œë¹„ìŠ¤ ë²”ìœ„ ì œí•œ)"""
    try:
        data = request.get_json()
        sources = data.get('sources', ['reb_api'])
        regions = data.get('regions', [])
        
        # ì§€ì—­ ê²€ì¦
        if regions:
            valid, unsupported = region_service.validate_region_request(regions)
            if not valid:
                return jsonify({
                    'status': 'error',
                    'message': f'ì§€ì›í•˜ì§€ ì•ŠëŠ” ì§€ì—­ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤: {unsupported}',
                    'supported_regions': region_service.get_regions_for_api()
                }), 400
        else:
            # ê¸°ë³¸ ì§€ì—­ ì‚¬ìš©
            regions = region_service.get_default_regions()
            print(f"ê¸°ë³¸ ì§€ì—­ ì‚¬ìš©: {regions}")
        
        all_results = {}
        
        for source in sources:
            if source == 'reb_api':
                # REB API í¬ë¡¤ëŸ¬ ì‚¬ìš©
                reb_crawler = REBAPICrawler()
                results = reb_crawler.crawl_all_regions(regions)
                all_results['reb_api'] = results
                
            elif source == 'public_data':
                # ê³µê³µë°ì´í„°í¬í„¸ API ì‚¬ìš©
                public_crawler = PublicDataCrawler()
                results = public_crawler.crawl_all_regions(regions)
                all_results['public_data'] = results
                
            elif source == 'web_scraping':
                # ì›¹ ìŠ¤í¬ë˜í•‘ ì‚¬ìš© (ì„ íƒì , CI/ë°°í¬ í™˜ê²½ì—ì„œëŠ” selenium ë¯¸ì„¤ì¹˜ ê°€ëŠ¥)
                if WebScraper is None:
                    all_results['web_scraping'] = {
                        'status': 'disabled',
                        'reason': 'selenium not installed in this environment'
                    }
                else:
                    web_scraper = WebScraper()
                    try:
                        results = web_scraper.crawl_all_regions(regions)
                        all_results['web_scraping'] = results
                    finally:
                        web_scraper.close()
                    

                
            elif source == 'asil':
                # ì•„ì‹¤ í¬ë¡¤ë§ ì‚¬ìš© (ì„ íƒì , CI/ë°°í¬ í™˜ê²½ì—ì„œëŠ” selenium ë¯¸ì„¤ì¹˜ ê°€ëŠ¥)
                if AsilCrawler is None:
                    all_results['asil'] = {
                        'status': 'disabled',
                        'reason': 'selenium not installed in this environment'
                    }
                else:
                    asil_crawler = AsilCrawler()
                    try:
                        results = asil_crawler.crawl_all_regions(regions)
                        all_results['asil'] = results
                    finally:
                        asil_crawler.close()
                    
            elif source == 'molit_api':
                # êµ­í† êµí†µë¶€ API ì‚¬ìš© (ì„ íƒì , CI í™˜ê²½ì—ì„œëŠ” pandas ë¯¸ì„¤ì¹˜ ê°€ëŠ¥)
                if MolitAPICrawler is None:
                    all_results['molit_api'] = {
                        'status': 'disabled',
                        'reason': 'pandas/numpy not installed in this environment'
                    }
                else:
                    molit_crawler = MolitAPICrawler()
                    results = molit_crawler.crawl_all_regions(regions)
                    all_results['molit_api'] = results
                
            elif source == 'molit_web':
                # êµ­í† êµí†µë¶€ ì›¹ì‚¬ì´íŠ¸ í¬ë¡¤ë§ ì‚¬ìš© (ë°°í¬ í™˜ê²½ì—ì„œëŠ” ê¸°ë³¸ ë¹„í™œì„±í™”)
                if MolitWebCrawler is None:
                    all_results['molit_web'] = {
                        'status': 'disabled',
                        'reason': 'molit web crawler dependencies are not available in this environment'
                    }
                else:
                    molit_web_crawler = MolitWebCrawler()
                    results = {}
                    for region in regions:
                        region_results = molit_web_crawler.crawl_region_data(region, months=24)
                        results[region] = region_results
                    all_results['molit_web'] = results
        
        return jsonify({
            'status': 'success',
            'message': 'ë°ì´í„° ìˆ˜ì§‘ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.',
            'results': all_results
        })
        
    except Exception as e:
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 500

@app.route('/api/statistics', methods=['GET'])
def get_statistics():
    """í†µê³„ ë°ì´í„° ì¡°íšŒ"""
    region = request.args.get('region', '')
    
    conn = sqlite3.connect('realstate.db')
    cursor = conn.cursor()
    
    # ì „ì²´ ê±°ë˜ëŸ‰
    query = '''
        SELECT 
            COUNT(*) as total_transactions,
            AVG(avg_price) as avg_price,
            SUM(transaction_count) as total_count
        FROM transactions
        WHERE 1=1
    '''
    params = []
    
    if region:
        query += ' AND region_name = ?'
        params.append(region)
    
    cursor.execute(query, params)
    stats = cursor.fetchone()
    
    # ìµœê·¼ 30ì¼ ê°€ê²©ë³€ë™ë¥ 
    cursor.execute('''
        SELECT AVG(price_change_rate) 
        FROM price_changes 
        WHERE date >= date('now', '-30 days')
    ''')
    price_change = cursor.fetchone()[0] or 0
    
    conn.close()
    
    return jsonify({
        'total_transactions': stats[0],
        'avg_price': stats[1],
        'total_count': stats[2],
        'price_change_30d': price_change
    })

@app.route('/api/rankings/volume', methods=['GET'])
def get_volume_rankings():
    """ê±°ë˜ëŸ‰ ìˆœìœ„ ì¡°íšŒ"""
    try:
        conn = sqlite3.connect('realstate.db')
        cursor = conn.cursor()
        
        # ê°„ë‹¨í•œ ì¿¼ë¦¬ë¡œ í…ŒìŠ¤íŠ¸
        cursor.execute('SELECT COUNT(*) FROM transactions')
        count = cursor.fetchone()[0]
        
        if count == 0:
            # ìƒ˜í”Œ ë°ì´í„° ë°˜í™˜
            rankings = [
                {
                    'rank': 1,
                    'region_name': 'ì„œìš¸ ê°•ë‚¨êµ¬',
                    'total_volume': 150,
                    'avg_price': 800000000,
                    'transaction_count': 1
                },
                {
                    'rank': 2,
                    'region_name': 'ì„œìš¸ ì„œì´ˆêµ¬',
                    'total_volume': 120,
                    'avg_price': 750000000,
                    'transaction_count': 1
                },
                {
                    'rank': 3,
                    'region_name': 'ë¶€ì‚° í•´ìš´ëŒ€êµ¬',
                    'total_volume': 100,
                    'avg_price': 500000000,
                    'transaction_count': 1
                }
            ]
        else:
            query = '''
                SELECT 
                    region_name,
                    SUM(transaction_count) as total_volume,
                    AVG(avg_price) as avg_price,
                    COUNT(*) as transaction_count
                FROM transactions
                GROUP BY region_name
                ORDER BY total_volume DESC
                LIMIT 20
            '''
            
            cursor.execute(query)
            rankings = []
            
            for i, row in enumerate(cursor.fetchall(), 1):
                rankings.append({
                    'rank': i,
                    'region_name': row[0],
                    'total_volume': row[1],
                    'avg_price': row[2],
                    'transaction_count': row[3]
                })
        
        conn.close()
        return jsonify(rankings)
        
    except Exception as e:
        print(f"Error in get_volume_rankings: {str(e)}")
        return jsonify([])

@app.route('/api/rankings/price-change', methods=['GET'])
def get_price_change_rankings():
    """ê°€ê²©ë³€ë™ë¥  ìˆœìœ„ ì¡°íšŒ"""
    try:
        conn = sqlite3.connect('realstate.db')
        cursor = conn.cursor()
        
        # ê°„ë‹¨í•œ ì¿¼ë¦¬ë¡œ í…ŒìŠ¤íŠ¸
        cursor.execute('SELECT COUNT(*) FROM price_changes')
        count = cursor.fetchone()[0]
        
        if count == 0:
            # ìƒ˜í”Œ ë°ì´í„° ë°˜í™˜
            rankings = [
                {
                    'rank': 1,
                    'region_name': 'ì„œìš¸ ê°•ë‚¨êµ¬',
                    'avg_change_rate': 2.5,
                    'max_price': 850000000,
                    'min_price': 750000000
                },
                {
                    'rank': 2,
                    'region_name': 'ì„œìš¸ ì„œì´ˆêµ¬',
                    'avg_change_rate': 2.1,
                    'max_price': 800000000,
                    'min_price': 700000000
                },
                {
                    'rank': 3,
                    'region_name': 'ë¶€ì‚° í•´ìš´ëŒ€êµ¬',
                    'avg_change_rate': 1.8,
                    'max_price': 550000000,
                    'min_price': 450000000
                }
            ]
        else:
            query = '''
                SELECT 
                    region_name,
                    AVG(price_change_rate) as avg_change_rate,
                    MAX(avg_price) as max_price,
                    MIN(avg_price) as min_price
                FROM price_changes
                GROUP BY region_name
                ORDER BY avg_change_rate DESC
                LIMIT 20
            '''
            
            cursor.execute(query)
            rankings = []
            
            for i, row in enumerate(cursor.fetchall(), 1):
                rankings.append({
                    'rank': i,
                    'region_name': row[0],
                    'avg_change_rate': row[1],
                    'max_price': row[2],
                    'min_price': row[3]
                })
        
        conn.close()
        return jsonify(rankings)
        
    except Exception as e:
        print(f"Error in get_price_change_rankings: {str(e)}")
        return jsonify([])

@app.route('/api/rankings/price', methods=['GET'])
def get_price_rankings():
    """í‰ê·  ê°€ê²© ìˆœìœ„ ì¡°íšŒ"""
    try:
        conn = sqlite3.connect('realstate.db')
        cursor = conn.cursor()
        
        # ê°„ë‹¨í•œ ì¿¼ë¦¬ë¡œ í…ŒìŠ¤íŠ¸
        cursor.execute('SELECT COUNT(*) FROM transactions')
        count = cursor.fetchone()[0]
        
        if count == 0:
            # ìƒ˜í”Œ ë°ì´í„° ë°˜í™˜
            rankings = [
                {
                    'rank': 1,
                    'region_name': 'ì„œìš¸ ê°•ë‚¨êµ¬',
                    'avg_price': 800000000,
                    'total_volume': 150,
                    'transaction_count': 1
                },
                {
                    'rank': 2,
                    'region_name': 'ì„œìš¸ ì„œì´ˆêµ¬',
                    'avg_price': 750000000,
                    'total_volume': 120,
                    'transaction_count': 1
                },
                {
                    'rank': 3,
                    'region_name': 'ë¶€ì‚° í•´ìš´ëŒ€êµ¬',
                    'avg_price': 500000000,
                    'total_volume': 100,
                    'transaction_count': 1
                }
            ]
        else:
            query = '''
                SELECT 
                    region_name,
                    AVG(avg_price) as avg_price,
                    SUM(transaction_count) as total_volume,
                    COUNT(*) as transaction_count
                FROM transactions
                GROUP BY region_name
                ORDER BY avg_price DESC
                LIMIT 20
            '''
            
            cursor.execute(query)
            rankings = []
            
            for i, row in enumerate(cursor.fetchall(), 1):
                rankings.append({
                    'rank': i,
                    'region_name': row[0],
                    'avg_price': row[1],
                    'total_volume': row[2],
                    'transaction_count': row[3]
                })
        
        conn.close()
        return jsonify(rankings)
        
    except Exception as e:
        print(f"Error in get_price_rankings: {str(e)}")
        return jsonify([])

@app.route('/api/market-overview', methods=['GET'])
def get_market_overview():
    """ì‹œì¥ ê°œìš” ë°ì´í„°"""
    conn = sqlite3.connect('realstate.db')
    cursor = conn.cursor()
    
    # ì „ì²´ ê±°ë˜ëŸ‰
    cursor.execute('''
        SELECT SUM(transaction_count) 
        FROM transactions 
        WHERE date >= date('now', '-30 days')
    ''')
    total_volume = cursor.fetchone()[0] or 0
    
    # í‰ê·  ê°€ê²©
    cursor.execute('''
        SELECT AVG(avg_price) 
        FROM transactions 
        WHERE date >= date('now', '-30 days')
    ''')
    avg_price = cursor.fetchone()[0] or 0
    
    # ê°€ê²©ë³€ë™ë¥ 
    cursor.execute('''
        SELECT AVG(price_change_rate) 
        FROM price_changes 
        WHERE date >= date('now', '-30 days')
    ''')
    price_change = cursor.fetchone()[0] or 0
    
    # ê±°ë˜ëŸ‰ ë³€í™”ìœ¨ (ìµœê·¼ 30ì¼ vs ì´ì „ 30ì¼)
    cursor.execute('''
        SELECT SUM(transaction_count) 
        FROM transactions 
        WHERE date >= date('now', '-60 days') AND date < date('now', '-30 days')
    ''')
    prev_volume = cursor.fetchone()[0] or 1  # 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€
    
    # ê±°ë˜ëŸ‰ ë³€í™”ìœ¨ ê³„ì‚°
    if prev_volume > 0:
        volume_change = ((total_volume - prev_volume) / prev_volume) * 100
    else:
        volume_change = 0
    
    # ê±°ë˜ í™œì„± ì§€ì—­ ìˆ˜
    cursor.execute('''
        SELECT COUNT(DISTINCT region_name) 
        FROM transactions 
        WHERE date >= date('now', '-30 days')
    ''')
    active_regions = cursor.fetchone()[0] or 0
    
    conn.close()
    
    return jsonify({
        'total_volume': total_volume,
        'avg_price': avg_price,
        'price_change': price_change,
        'volume_change': volume_change,
        'active_regions': active_regions
    })

@app.route('/api/apartments/rankings', methods=['GET'])
def get_apartment_rankings():
    """ì‹œêµ°êµ¬ë³„ ì•„íŒŒíŠ¸ ìˆœìœ„ (30ìœ„ê¹Œì§€)"""
    try:
        region = request.args.get('region', '')
        period = int(request.args.get('period', 30))
        month = request.args.get('month', '')
        
        print(f"ì•„íŒŒíŠ¸ ìˆœìœ„ ì¡°íšŒ: region={region}, period={period}, month={month}")
        
        conn = sqlite3.connect('realstate.db')
        cursor = conn.cursor()
        
        # ë¨¼ì € ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
        cursor.execute('SELECT COUNT(*) FROM transactions')
        total_count = cursor.fetchone()[0]
        print(f"ì´ ê±°ë˜ ë°ì´í„°: {total_count}ê±´")
        
        # ì›”ë³„ í•„í„° ì¡°ê±´ ì„¤ì •
        if month:
            # íŠ¹ì • ì›” ë°ì´í„° ì¡°íšŒ
            year = month[:4]
            month_num = month[4:6]
            date_filter = f"AND strftime('%Y%m', date) = '{month}'"
        else:
            # ê¸°ê°„ í•„í„° ì ìš©
            date_filter = f"AND date >= date('now', '-' || {period} || ' days')"
        
        if region:
            # íŠ¹ì • ì‹œêµ°êµ¬ì˜ ì•„íŒŒíŠ¸ ìˆœìœ„
            query = f'''
                SELECT 
                    complex_name,
                    AVG(avg_price) as avg_price,
                    COUNT(*) as transaction_count,
                    0 as avg_area,
                    0 as avg_floor,
                    MAX(latest_transaction_date) as latest_transaction_date
                FROM transactions
                WHERE region_name = ? 
                {date_filter}
                GROUP BY complex_name
                ORDER BY avg_price DESC
                LIMIT 30
            '''
            cursor.execute(query, (region,))
        else:
            # ì „ì²´ ì•„íŒŒíŠ¸ ìˆœìœ„
            query = f'''
                SELECT 
                    region_name,
                    complex_name,
                    AVG(avg_price) as avg_price,
                    COUNT(*) as transaction_count,
                    0 as avg_area,
                    0 as avg_floor,
                    MAX(latest_transaction_date) as latest_transaction_date
                FROM transactions
                WHERE 1=1
                {date_filter}
                GROUP BY region_name, complex_name
                ORDER BY avg_price DESC
                LIMIT 30
            '''
            cursor.execute(query)
        
        rows = cursor.fetchall()
        print(f"ì¡°íšŒëœ ì•„íŒŒíŠ¸ ë°ì´í„°: {len(rows)}ê±´")
        
        if len(rows) > 0:
            print(f"ì²« ë²ˆì§¸ í–‰: {rows[0]}")
        
        rankings = []
        for i, row in enumerate(rows, 1):
            try:
                if region:
                    rankings.append({
                        'rank': i,
                        'complex_name': row[0],
                        'avg_price': row[1],
                        'transaction_count': row[2],
                        'avg_area': row[3],
                        'avg_floor': row[4],
                        'latest_transaction_date': row[5]
                    })
                else:
                    rankings.append({
                        'rank': i,
                        'region_name': row[0],
                        'complex_name': row[1],
                        'avg_price': row[2],
                        'transaction_count': row[3],
                        'avg_area': row[4],
                        'avg_floor': row[5],
                        'latest_transaction_date': row[6]
                    })
            except Exception as e:
                print(f"í–‰ ì²˜ë¦¬ ì˜¤ë¥˜ (í–‰ {i}): {str(e)}, ë°ì´í„°: {row}")
        
        conn.close()
        print(f"ë°˜í™˜í•  ìˆœìœ„ ë°ì´í„°: {len(rankings)}ê±´")
        return jsonify(rankings)
        
    except Exception as e:
        print(f"Error in get_apartment_rankings: {str(e)}")
        return jsonify([])

if __name__ == '__main__':
    port = int(os.environ.get('PORT', 5002))
    app.run(debug=False, host='0.0.0.0', port=port) 